{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIDs7xacLJsQ",
        "outputId": "94a8135a-5168-43bd-806e-c560049a3d1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Shravya H Jain\\sentimental analysis\\Study_Genie\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: True\n",
            "GPU name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
            "WARNING:tensorflow:From c:\\Users\\Shravya H Jain\\sentimental analysis\\Study_Genie\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Renewable energy has become a pivotal topic in the global conversation about sustainable development and climate change. The shift towards renewable energy sources such as solar, wind, hydro, and geothermal power is increasingly seen as a crucial strategy for reducing greenhouse gas emissions. The intermittent nature of solar and wind energy requires the development of efficient energy storage solutions to ensure a stable power supply.\n"
          ]
        }
      ],
      "source": [
        "# from transformers import pipeline\n",
        "\n",
        "# # Load the summarization pipeline\n",
        "# summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# # Sample text to summarize\n",
        "# text = \"\"\"\n",
        "# Hugging Face is a company specializing in natural language processing. They are best known for their work on transformer models and the open-source library, `transformers`, which provides pre-trained models for various NLP tasks. Their library is widely used in both academia and industry to tackle challenges in language understanding and generation.\n",
        "# \"\"\"\n",
        "\n",
        "# # Generate summary\n",
        "# summary = summarizer(text, max_length=50, min_length=25, do_sample=True)\n",
        "# print(summary[0]['summary_text'])\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
        "\n",
        "# Load a different summarization model\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Updated sample text to summarize\n",
        "text = \"\"\"\n",
        "Renewable energy has become a pivotal topic in the global conversation about sustainable development and climate change. As the world grapples with the consequences of fossil fuel consumption, the shift towards renewable energy sources such as solar, wind, hydro, and geothermal power is increasingly seen as a crucial strategy for reducing greenhouse gas emissions and mitigating environmental damage.\n",
        "\n",
        "Solar energy harnesses the power of the sun through photovoltaic cells, converting sunlight directly into electricity. This technology has seen remarkable advancements over the past decade, with decreasing costs and increasing efficiency making solar power a viable option for both residential and commercial applications. Wind energy, captured through wind turbines, also contributes significantly to the renewable energy mix. Onshore and offshore wind farms have proliferated, taking advantage of wind patterns to generate large amounts of electricity.\n",
        "\n",
        "Hydropower, which utilizes flowing water to generate energy, has been a longstanding source of renewable energy. While it provides a stable and consistent supply of electricity, large-scale hydroelectric projects can have significant environmental and social impacts, including effects on aquatic ecosystems and local communities. Geothermal energy, derived from the heat of the Earthâ€™s interior, offers a reliable and sustainable source of power with relatively low environmental impact.\n",
        "\n",
        "Despite these advancements, the transition to renewable energy faces several challenges. The intermittent nature of solar and wind energy requires the development of efficient energy storage solutions to ensure a stable power supply. Additionally, the integration of renewable energy sources into existing power grids necessitates significant infrastructure upgrades and technological innovations.\n",
        "\n",
        "Policy and regulatory frameworks also play a critical role in supporting the growth of renewable energy. Governments around the world are implementing incentives and subsidies to encourage the adoption of clean energy technologies. However, the effectiveness of these measures varies by region and depends on local economic, political, and social factors.\n",
        "\n",
        "The shift towards renewable energy represents not only an opportunity to combat climate change but also a chance to drive economic growth and create jobs in emerging industries. As technology continues to evolve and costs decrease, the potential for renewable energy to meet a significant portion of global energy demands becomes increasingly achievable. However, achieving a sustainable energy future will require continued innovation, investment, and collaboration across all sectors of society.\n",
        "\"\"\"\n",
        "\n",
        "# Generate summary with adjusted parameters\n",
        "summary = summarizer(text, max_length=150, min_length=70, do_sample=True)\n",
        "print(summary[0]['summary_text'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfM6rKhvUzly",
        "outputId": "14e8b5be-957c-4514-c0b5-f2775f80538f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JepzakWbLLHv",
        "outputId": "0ed21abc-3780-4336-c088-629db7b9aa42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpNVWPb9mINg",
        "outputId": "4853fbe7-eaf6-4e86-f664-2a0f2773471b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Shravya H Jain\\sentimental analysis\\Study_Genie\\.venv\\lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits: tf.Tensor([[ 0.36169833 -0.17030086]], shape=(1, 2), dtype=float32)\n",
            "Probabilities: tf.Tensor([[0.62994933 0.37005073]], shape=(1, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Example text\n",
        "text = \"Hello, world!\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(text, return_tensors=\"tf\")\n",
        "\n",
        "# Perform inference\n",
        "outputs = model(inputs)\n",
        "\n",
        "# Extract logits\n",
        "logits = outputs.logits\n",
        "\n",
        "# Apply softmax to get probabilities\n",
        "probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "# Print logits and probabilities\n",
        "print(\"Logits:\", logits)\n",
        "print(\"Probabilities:\", probabilities)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOTcrC57qC_a",
        "outputId": "ed43712c-b1f2-40ec-f3bb-c50958330fc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "inputs = tokenizer(\"Hello, world!\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xE5NdPdqWH6",
        "outputId": "ffcef22a-8c89-4c42-fde4-c79f014f726f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits: tensor([[ 0.2460, -0.0803]])\n",
            "Probabilities: tensor([[0.5808, 0.4192]])\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Example text\n",
        "text = \"Hello, world!\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Extract logits\n",
        "logits = outputs.logits\n",
        "\n",
        "# Apply softmax to get probabilities\n",
        "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "# Print logits and probabilities\n",
        "print(\"Logits:\", logits)\n",
        "print(\"Probabilities:\", probabilities)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdcvjRagrEb9",
        "outputId": "8ac6a3d7-032a-4ed6-aa80-e2af3ef2d4f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Shravya H Jain\\sentimental analysis\\Study_Genie\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits: tensor([[-0.0126,  0.1618]])\n",
            "Probabilities: tensor([[0.4565, 0.5435]])\n",
            "Predicted class: Positive\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Example text\n",
        "text = \"I love this product.\"\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Extract logits\n",
        "logits = outputs.logits\n",
        "\n",
        "# Apply softmax to get probabilities\n",
        "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "# Get predicted class\n",
        "predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "# Define class labels\n",
        "class_labels = [\"Negative\",\"Positive\"]\n",
        "\n",
        "# Print results\n",
        "print(\"Logits:\", logits)\n",
        "print(\"Probabilities:\", probabilities)\n",
        "print(\"Predicted class:\", class_labels[predicted_class])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer saved to: ./bert_sentiment_model\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Define save directory\n",
        "save_dir = \"./bert_sentiment_model\"  # Local folder to save\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "print(f\"Model and tokenizer saved to: {save_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# # Load from saved directory\n",
        "# save_dir = \"./bert_sentiment_model\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(save_dir)\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(save_dir)\n",
        "\n",
        "# # Verify it works\n",
        "# text = \"I love this product.\"\n",
        "# inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "# outputs = model(**inputs)\n",
        "# print(\"Reloaded model outputs:\", outputs.logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "aIcN1O_0wsYg",
        "outputId": "3b183f4b-e4d4-486c-b12f-1fb0b61ded6b"
      },
      "outputs": [],
      "source": [
        "# from transformers import pipeline\n",
        "# import PyPDF2\n",
        "\n",
        "# # Load the summarization model\n",
        "# summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# # Extract text from PDF\n",
        "# def extract_text_from_pdf(pdf_path):\n",
        "#     text = \"\"\n",
        "#     with open(pdf_path, \"rb\") as file:\n",
        "#         reader = PyPDF2.PdfReader(file)\n",
        "#         for page in range(reader.numPages):\n",
        "#             text += reader.getPage(page).extract_text()\n",
        "#     return text\n",
        "\n",
        "# # Path to your PDF\n",
        "# pdf_path = f\"/content/LAST HALF (1)_merged (1).pdf\"\n",
        "# text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# # Generate summary\n",
        "# summary = summarizer(text, max_length=150, min_length=30, do_sample=False)\n",
        "# print(summary[0]['summary_text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW3SLj-aDM20",
        "outputId": "e145fb74-cb2c-4333-c56a-f1e1e28325f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "Your max_length is set to 150, but your input_length is only 9. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Java is a high-le vel, object-oriented, secur e, and r obust platform-independent language. It is extensiv ely used in industries. 15 Most Asked Java Programming Interview Questions You Should Know. In Java Identifiers are the names of variables, classes, packages, methods, and interfaces. Identifiers should be unique and can only ha ve alphanumeric char acters and underscor e in them. Reser ved keywor ds can not be used as identifier. Ans: In Java static is a keyword. It is used to manage the memory to make the efficient use of memory. Any variable declared with the static keyword is known as the static variable. Runnable- when a newborn thread is made, it is runnable. remains in the same state till the time program starts. Timed Waiting- When another thread is performing the task a thread has to wait. Terminated(Dead)- When a thread completes its task or terminates otherwise it enters the dead stage. A string pool is a storage area in the Java heap where the string literals are stored. It is also referred to as String Constant pool or String Intern pool. In JVM the string class keeps a pool of strings to decrease the number of string objects. In loops when required to terminate the loop at a given condition, we use a break statement in Java. The break statement immediately terminates the loop and control of the program move to the next statement following the loop. Ans: Pointers are not so simple and a bit unsafe to be used by beginner programmers. Java is made to be simple and pointers can complicate it. It can also cause potential errors. Ans: References are shared in different functions and the String pool can be changed using the same shared references from anywhere. securityissues if pointers are used as the user can directly access memory with help of pointers. Also, the use of pointers may hinder the performance of the java language. Happy Learning. Scaler Topics . Happy Learning! Click here for more information on Scaler topics. Click here to read more Scaler articles.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import PyPDF2\n",
        "import textwrap\n",
        "\n",
        "# Load the summarization model\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page in range(len(reader.pages)):\n",
        "            text += reader.pages[page].extract_text()\n",
        "    return text\n",
        "\n",
        "# Function to summarize text in chunks\n",
        "def summarize_text(text, chunk_size=1000):\n",
        "    chunks = textwrap.wrap(text, chunk_size)\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        summary = summarizer(chunk, max_length=150, min_length=30, do_sample=False)\n",
        "        summaries.append(summary[0]['summary_text'])\n",
        "    return \" \".join(summaries)\n",
        "\n",
        "# Path to your PDF\n",
        "pdf_path = \"15.pdf\"\n",
        "\n",
        "# Extract text from the PDF file\n",
        "text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# Generate summary\n",
        "summary = summarize_text(text)\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Xx3RE6cvx4ue",
        "outputId": "2e29ceca-a4f8-4175-982d-e2afd737b9d2"
      },
      "outputs": [],
      "source": [
        "# from transformers import pipeline\n",
        "# import PyPDF2\n",
        "\n",
        "# # Load the summarization model\n",
        "# summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# # Extract text from PDF\n",
        "# def extract_text_from_pdf(pdf_path):\n",
        "#     text = \"\"\n",
        "#     with open(pdf_path, \"rb\") as file:\n",
        "#         reader = PyPDF2.PdfFileReader(file)\n",
        "#         for page in range(reader.numPages):\n",
        "#             text += reader.getPage(page).extract_text()\n",
        "#     return text\n",
        "\n",
        "# # Path to your PDF\n",
        "# pdf_path = f\"/content/{javalaboratory(1).pdf}\"  # Make sure this file is in your working directory\n",
        "# text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# # Generate summary\n",
        "# summary = summarizer(text, max_length=150, min_length=30, do_sample=False)\n",
        "# print(summary[0]['summary_text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "Ez1K4A9-4ZgV",
        "outputId": "0cbb3c2f-93d0-423e-bdf5-03b53317f635"
      },
      "outputs": [],
      "source": [
        "# from transformers import pipeline\n",
        "# import PyPDF2\n",
        "# from google.colab import files\n",
        "\n",
        "# # Load the summarization model\n",
        "# summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# # Function to extract text from PDF\n",
        "# def extract_text_from_pdf(pdf_path):\n",
        "#     text = \"\"\n",
        "#     with open(pdf_path, \"rb\") as file:\n",
        "#         reader = PyPDF2.PdfReader(file)\n",
        "#         for page in range(reader.len(reader.pages)):\n",
        "#             text += reader.getPage(page).extract_text()\n",
        "#     return text\n",
        "\n",
        "# # Upload the file\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# # Check if any files were uploaded\n",
        "# if not uploaded:\n",
        "#     print(\"No files uploaded.\")\n",
        "# else:\n",
        "#     # Save the uploaded file to the /content directory\n",
        "#     for filename in uploaded.keys():\n",
        "#         file_path = f\"/content/{filename}\"\n",
        "#         with open(file_path, \"wb\") as f:\n",
        "#             f.write(uploaded[filename])\n",
        "#         print(f\"File uploaded and saved to: {file_path}\")\n",
        "\n",
        "#     # Define the path to your PDF\n",
        "#     # Define the path to your PDF\n",
        "#     pdf_path = \"/content/Java Laboratory (1).pdf\"\n",
        "\n",
        "\n",
        "#     # Extract text from the PDF file\n",
        "#     try:\n",
        "#         text = extract_text_from_pdf(pdf_path)\n",
        "#         # Generate summary\n",
        "#         summary = summarizer(text, max_length=150, min_length=30, do_sample=False)\n",
        "#         print(summary[0]['summary_text'])\n",
        "#     except FileNotFoundError as e:\n",
        "#         print(f\"Error: {e}\")\n",
        "# from transformers import pipeline\n",
        "# import PyPDF2\n",
        "# from google.colab import files\n",
        "\n",
        "# # Load the summarization model\n",
        "# summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# # Function to extract text from PDF using PdfReader\n",
        "# def extract_text_from_pdf(pdf_path):\n",
        "#     text = \"\"\n",
        "#     with open(pdf_path, \"rb\") as file:\n",
        "#         reader = PyPDF2.PdfReader(file)\n",
        "#         for page in reader.pages:\n",
        "#             text += page.extract_text() or \"\"  # Ensure empty string if text extraction fails\n",
        "#     return text\n",
        "\n",
        "# # Upload the file\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# # Save the uploaded file to the /content directory\n",
        "# for filename in uploaded.keys():\n",
        "#     # Save the file to the path\n",
        "#     file_path = f\"/content/Java Laboratory (1).pdf\"\n",
        "#     with open(file_path, \"wb\") as f:\n",
        "#         f.write(uploaded[filename])\n",
        "\n",
        "# # Path to your PDF\n",
        "# pdf_path = file_path\n",
        "\n",
        "# # Extract text from the PDF file\n",
        "# text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# # Generate summary\n",
        "# summary = summarizer(text, max_length=150, min_length=30, do_sample=False)\n",
        "# print(summary[0]['summary_text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file: c:\\Users\\Shravya H Jain\\sentimental analysis\\Study_Genie\\15.pdf\n",
            "Generating summary...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your max_length is set to 150, but your input_length is only 9. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== SUMMARY ===\n",
            " Java is a high-le vel, object-oriented, secur e, and r obust platform-independent language. It is extensiv ely used in industries. 15 Most Asked Java Programming Interview Questions You Should Know. In Java Identifiers are the names of variables, classes, packages, methods, and interfaces. Identifiers should be unique and can only ha ve alphanumeric char acters and underscor e in them. Reser ved keywor ds can not be used as identifier.  Static means class level in java and it is a non-access modifier. We can apply the Static keyword to methods, variables, and nested classes only. Any variable declared with the static keyword is known as the static variable. When a newborn thread is made, it is runnable. It remains in the same state till the time program starts. Timed Waiting- When another thread is performing the task a thread has to wait. Terminated(Dead)- When a thread completes its task or terminates otherwise it enters the dead stage. Ans: A string pool is a storage area in the Java heap where the string literals are stored. It is empty by default and when we a string is created, it occupies some memory in the java heap privately maintained by the Java script class. In loops when required to terminate the loop at a given condition, we use a break statement in Java. The break statement immediately terminates the loop and control of the program move to the next statement following the loop. Ans: Pointers are not so simple and a bit unsafe to be used by beginner programmers. Java is made to be simple and pointers can complicate it. Ans: References are shared in different functions and the String pool can be changed using the same shared references from anywhere. security issues if pointers are used as the user can directly access memory. Also, the use of pointers may hinder the performance of the java language. Happy Learning. Scaler Topics . Happy Learning! Click here for more information on Scaler topics. Click here to read more Scaler articles.\n",
            "\n",
            "Summary saved to: c:\\Users\\Shravya H Jain\\sentimental analysis\\Study_Genie\\summary_15.pdf.txt\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import PyPDF2\n",
        "import textwrap\n",
        "import os\n",
        "\n",
        "# Load the summarization model\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from PDF file\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, \"rb\") as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"  # Add newline between pages\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Failed to read PDF: {str(e)}\")\n",
        "    return text\n",
        "\n",
        "def summarize_text(text, chunk_size=1000):\n",
        "    \"\"\"Summarize text in manageable chunks\"\"\"\n",
        "    if not text.strip():\n",
        "        return \"No text available for summarization.\"\n",
        "    \n",
        "    chunks = textwrap.wrap(text, chunk_size)\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        try:\n",
        "            summary = summarizer(\n",
        "                chunk,\n",
        "                max_length=150,\n",
        "                min_length=30,\n",
        "                do_sample=False\n",
        "            )\n",
        "            summaries.append(summary[0]['summary_text'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing chunk: {str(e)}\")\n",
        "            continue\n",
        "    \n",
        "    return \" \".join(summaries) if summaries else \"Summary generation failed.\"\n",
        "\n",
        "def main():\n",
        "    # Specify your PDF file name\n",
        "    pdf_name = \"15.pdf\"\n",
        "    \n",
        "    # Get the current working directory (works in both .py files and notebooks)\n",
        "    script_dir = os.getcwd()\n",
        "    pdf_path = os.path.join(script_dir, pdf_name)\n",
        "    \n",
        "    print(f\"Processing file: {pdf_path}\")\n",
        "    \n",
        "    try:\n",
        "        # Check if file exists\n",
        "        if not os.path.exists(pdf_path):\n",
        "            raise FileNotFoundError(f\"PDF file not found at: {pdf_path}\")\n",
        "        \n",
        "        # Extract text from the PDF\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        \n",
        "        if not text.strip():\n",
        "            print(\"Warning: The PDF appears to be empty or contains no text.\")\n",
        "            return\n",
        "        \n",
        "        # Generate summary\n",
        "        print(\"Generating summary...\")\n",
        "        summary = summarize_text(text)\n",
        "        \n",
        "        # Print and save the summary\n",
        "        print(\"\\n=== SUMMARY ===\")\n",
        "        print(summary)\n",
        "        \n",
        "        # Save summary to file\n",
        "        summary_path = os.path.join(script_dir, f\"summary_{pdf_name}.txt\")\n",
        "        with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(summary)\n",
        "        print(f\"\\nSummary saved to: {summary_path}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztkn72B22pOr",
        "outputId": "f675b53c-2906-4dff-9ed2-1038f1b211af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Working Directory: c:\\Users\\Shravya H Jain\\sentimental analysis\\Study_Genie\n",
            "['.git', '.venv', '15.pdf', 'LICENSE', 'README.md', 'STUDYGENIE.ipynb', 'summary_15.pdf.txt']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Check the current working directory\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "\n",
        "print(os.listdir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaY3BPZQx4xR",
        "outputId": "972db5e2-1948-4a12-e656-900a30e2ec80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (3.0.1)\n",
            "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\shravya h jain\\sentimental analysis\\study_genie\\.venv\\lib\\site-packages (from PyPDF2) (4.13.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install  PyPDF2"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN/S+i8mcuNXqDREPUa6Kzm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
